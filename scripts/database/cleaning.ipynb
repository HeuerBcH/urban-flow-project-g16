{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eebb4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9beed98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório atual: c:\\Users\\berna\\OneDrive\\Documentos\\Computação\\projetos\\urban-flow-project-g16\\scripts\\database\n",
      "Diretório do projeto: c:\\Users\\berna\\OneDrive\\Documentos\\Computação\\projetos\\urban-flow-project-g16\n",
      "Diretório de dados brutos: c:\\Users\\berna\\OneDrive\\Documentos\\Computação\\projetos\\urban-flow-project-g16\\data\\raw\n",
      "README.md existe: True\n",
      "Pasta data/raw existe: True\n",
      "Arquivos em data/raw: ['equipamentos-de-medicao-de-velocidade.csv', 'faixaazul.geojson', 'fluxo-veiculos-hora-janeiro.csv', 'fluxo-velocidade-em-quinze-minutos-foto-jan-2025.csv', 'lista-de-semaforos.csv', 'monitoramento-cttu.csv', 'relatorio-fluxo-de-15-em-15-minutos-lomb-abr-25.csv', 'relatorio-fluxo-de-15-em-15-minutos-lomb-ago-25.csv', 'relatorio-fluxo-de-15-em-15-minutos-lomb-fev-25.csv', 'relatorio-fluxo-de-15-em-15-minutos-lomb-jan-25.csv', 'relatorio-fluxo-de-15-em-15-minutos-lomb-jul-25.csv', 'relatorio-fluxo-de-15-em-15-minutos-lomb-jun-25.csv', 'relatorio-fluxo-de-15-em-15-minutos-lomb-mai-25.csv', 'relatorio-fluxo-de-15-em-15-minutos-lomb-mar-25.csv']\n",
      "Carregando datasets disponíveis...\n",
      "[OK] lista-de-semaforos.csv carregado (712 registros)\n",
      "[OK] equipamentos-de-medicao-de-velocidade.csv carregado (62 registros)\n",
      "[OK] fluxo-veiculos-hora-janeiro.csv carregado (672 registros)\n",
      "[OK] fluxo-velocidade-em-quinze-minutos-foto-jan-2025.csv carregado (342796 registros)\n",
      "[OK] monitoramento-cttu.csv carregado (54 registros)\n",
      "[OK] relatorio-fluxo-de-15-em-15-minutos-lomb-jan-25.csv carregado (283999 registros)\n",
      "[OK] relatorio-fluxo-de-15-em-15-minutos-lomb-fev-25.csv carregado (273529 registros)\n",
      "[OK] relatorio-fluxo-de-15-em-15-minutos-lomb-mar-25.csv carregado (301067 registros)\n",
      "[OK] relatorio-fluxo-de-15-em-15-minutos-lomb-abr-25.csv carregado (292669 registros)\n",
      "[OK] relatorio-fluxo-de-15-em-15-minutos-lomb-mai-25.csv carregado (300932 registros)\n",
      "[OK] relatorio-fluxo-de-15-em-15-minutos-lomb-jun-25.csv carregado (289577 registros)\n",
      "[OK] relatorio-fluxo-de-15-em-15-minutos-lomb-jul-25.csv carregado (297149 registros)\n",
      "[OK] relatorio-fluxo-de-15-em-15-minutos-lomb-ago-25.csv carregado (298228 registros)\n",
      "\n",
      "Total de datasets carregados: 13\n"
     ]
    }
   ],
   "source": [
    "# Definir caminho base do projeto\n",
    "import os\n",
    "\n",
    "# Detectar o diretório do projeto (onde está o README.md)\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Diretório atual: {current_dir}\")\n",
    "\n",
    "# Procurar pelo diretório que contém o README.md\n",
    "project_root = current_dir\n",
    "while project_root != os.path.dirname(project_root):  # Enquanto não chegou na raiz\n",
    "    if os.path.exists(os.path.join(project_root, \"README.md\")):\n",
    "        break\n",
    "    project_root = os.path.dirname(project_root)\n",
    "\n",
    "# Se não encontrou, usar o diretório atual e subir 2 níveis (scripts/database -> scripts -> projeto)\n",
    "if not os.path.exists(os.path.join(project_root, \"README.md\")):\n",
    "    project_root = os.path.dirname(os.path.dirname(current_dir))\n",
    "\n",
    "data_raw_path = os.path.join(project_root, \"data\", \"raw\")\n",
    "\n",
    "print(f\"Diretório do projeto: {project_root}\")\n",
    "print(f\"Diretório de dados brutos: {data_raw_path}\")\n",
    "print(f\"README.md existe: {os.path.exists(os.path.join(project_root, 'README.md'))}\")\n",
    "print(f\"Pasta data/raw existe: {os.path.exists(data_raw_path)}\")\n",
    "\n",
    "# Listar arquivos na pasta data/raw para verificar\n",
    "if os.path.exists(data_raw_path):\n",
    "    print(f\"Arquivos em data/raw: {os.listdir(data_raw_path)}\")\n",
    "else:\n",
    "    print(\"[ERRO] Pasta data/raw nao encontrada!\")\n",
    "\n",
    "# Carregar os datasets disponíveis\n",
    "print(\"Carregando datasets disponíveis...\")\n",
    "\n",
    "# Lista de arquivos esperados e suas configurações\n",
    "arquivos_esperados = {\n",
    "    \"lista-de-semaforos.csv\": {\"sep\": \",\", \"encoding\": \"utf-8\"},\n",
    "    \"equipamentos-de-medicao-de-velocidade.csv\": {\"sep\": \",\", \"encoding\": \"utf-8\"},\n",
    "    \"fluxo-veiculos-hora-janeiro.csv\": {\"sep\": \";\", \"encoding\": \"utf-8\"},\n",
    "    \"fluxo-velocidade-em-quinze-minutos-foto-jan-2025.csv\": {\"sep\": \";\", \"encoding\": \"utf-8\"},\n",
    "    \"monitoramento-cttu.csv\": {\"sep\": \";\", \"encoding\": \"utf-8\"},\n",
    "    \"relatorio-fluxo-de-15-em-15-minutos-lomb-jan-25.csv\": {\"sep\": \";\", \"encoding\": \"utf-8\"},\n",
    "    \"relatorio-fluxo-de-15-em-15-minutos-lomb-fev-25.csv\": {\"sep\": \";\", \"encoding\": \"utf-8\"},\n",
    "    \"relatorio-fluxo-de-15-em-15-minutos-lomb-mar-25.csv\": {\"sep\": \";\", \"encoding\": \"utf-8\"},\n",
    "    \"relatorio-fluxo-de-15-em-15-minutos-lomb-abr-25.csv\": {\"sep\": \";\", \"encoding\": \"utf-8\"},\n",
    "    \"relatorio-fluxo-de-15-em-15-minutos-lomb-mai-25.csv\": {\"sep\": \";\", \"encoding\": \"utf-8\"},\n",
    "    \"relatorio-fluxo-de-15-em-15-minutos-lomb-jun-25.csv\": {\"sep\": \";\", \"encoding\": \"utf-8\"},\n",
    "    \"relatorio-fluxo-de-15-em-15-minutos-lomb-jul-25.csv\": {\"sep\": \";\", \"encoding\": \"utf-8\"},\n",
    "    \"relatorio-fluxo-de-15-em-15-minutos-lomb-ago-25.csv\": {\"sep\": \";\", \"encoding\": \"utf-8\"}\n",
    "}\n",
    "\n",
    "# Carregar apenas os arquivos que existem\n",
    "datasets_carregados = {}\n",
    "for arquivo, config in arquivos_esperados.items():\n",
    "    caminho_arquivo = os.path.join(data_raw_path, arquivo)\n",
    "    if os.path.exists(caminho_arquivo):\n",
    "        try:\n",
    "            df = pd.read_csv(caminho_arquivo, **config)\n",
    "            datasets_carregados[arquivo] = df\n",
    "            print(f\"[OK] {arquivo} carregado ({df.shape[0]} registros)\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERRO] Erro ao carregar {arquivo}: {e}\")\n",
    "    else:\n",
    "        print(f\"[AVISO] {arquivo} nao encontrado\")\n",
    "\n",
    "# Atribuir aos DataFrames principais (apenas os que existem)\n",
    "semaforos_df = datasets_carregados.get(\"lista-de-semaforos.csv\")\n",
    "equip_med_vel_df = datasets_carregados.get(\"equipamentos-de-medicao-de-velocidade.csv\")\n",
    "\n",
    "print(f\"\\nTotal de datasets carregados: {len(datasets_carregados)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4603abe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando datasets restantes...\n",
      "\n",
      "Status dos datasets:\n",
      "[OK] Semáforos: 712 registros\n",
      "[OK] Equipamentos de Medição de Velocidade: 62 registros\n",
      "[OK] Fluxo de Veículos por Hora: 672 registros\n",
      "[OK] Fluxo e Velocidade 15min: 342796 registros\n",
      "[OK] Monitoramento CTTU: 54 registros\n",
      "[OK] Relatório Fluxo Agosto: 298228 registros\n",
      "[OK] Relatório Fluxo Fevereiro: 273529 registros\n",
      "\n",
      "Total de datasets disponíveis: 7\n"
     ]
    }
   ],
   "source": [
    "# Carregar os datasets restantes\n",
    "print(\"Carregando datasets restantes...\")\n",
    "\n",
    "# Atribuir os datasets restantes\n",
    "fluxo_veiculos_hora_df = datasets_carregados.get(\"fluxo-veiculos-hora-janeiro.csv\")\n",
    "fluxo_velocidade_15min_df = datasets_carregados.get(\"fluxo-velocidade-em-quinze-minutos-foto-jan-2025.csv\")\n",
    "monitoramento_cttu_df = datasets_carregados.get(\"monitoramento-cttu.csv\")\n",
    "relatorio_fluxo_jan_df = datasets_carregados.get(\"relatorio-fluxo-de-15-em-15-minutos-lomb-jan-25.csv\")\n",
    "relatorio_fluxo_fev_df = datasets_carregados.get(\"relatorio-fluxo-de-15-em-15-minutos-lomb-fev-25.csv\")\n",
    "relatorio_fluxo_mar_df = datasets_carregados.get(\"relatorio-fluxo-de-15-em-15-minutos-lomb-mar-25.csv\")\n",
    "relatorio_fluxo_abr_df = datasets_carregados.get(\"relatorio-fluxo-de-15-em-15-minutos-lomb-abr-25.csv\")\n",
    "relatorio_fluxo_mai_df = datasets_carregados.get(\"relatorio-fluxo-de-15-em-15-minutos-lomb-mai-25.csv\")\n",
    "relatorio_fluxo_jun_df = datasets_carregados.get(\"relatorio-fluxo-de-15-em-15-minutos-lomb-jun-25.csv\")\n",
    "relatorio_fluxo_jul_df = datasets_carregados.get(\"relatorio-fluxo-de-15-em-15-minutos-lomb-jul-25.csv\")\n",
    "relatorio_fluxo_ago_df = datasets_carregados.get(\"relatorio-fluxo-de-15-em-15-minutos-lomb-ago-25.csv\")\n",
    "\n",
    "\n",
    "# Verificar quais datasets foram carregados com sucesso\n",
    "datasets_info = {\n",
    "    \"Semáforos\": semaforos_df,\n",
    "    \"Equipamentos de Medição de Velocidade\": equip_med_vel_df,\n",
    "    \"Fluxo de Veículos por Hora\": fluxo_veiculos_hora_df,\n",
    "    \"Fluxo e Velocidade 15min\": fluxo_velocidade_15min_df,\n",
    "    \"Monitoramento CTTU\": monitoramento_cttu_df,\n",
    "    \"Relatório Fluxo Agosto\": relatorio_fluxo_ago_df,\n",
    "    \"Relatório Fluxo Fevereiro\": relatorio_fluxo_fev_df\n",
    "}\n",
    "\n",
    "print(\"\\nStatus dos datasets:\")\n",
    "for nome, df in datasets_info.items():\n",
    "    if df is not None:\n",
    "        print(f\"[OK] {nome}: {df.shape[0]} registros\")\n",
    "    else:\n",
    "        print(f\"[ERRO] {nome}: Nao disponivel\")\n",
    "\n",
    "print(f\"\\nTotal de datasets disponíveis: {sum(1 for df in datasets_info.values() if df is not None)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4b66057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISE EXPLORATÓRIA DOS DATASETS ===\n",
      "\n",
      "[INFO] Semáforos:\n",
      "   - Dimensões: 712 linhas x 9 colunas\n",
      "   - Colunas: ['_id', 'semaforo', 'localizacao1', 'localizacao2', 'bairro', 'latitude', 'longitude', 'tipo', 'funcionamento']\n",
      "   - Tipos de dados:\n",
      "     * _id: int64\n",
      "     * semaforo: int64\n",
      "     * localizacao1: object\n",
      "     * localizacao2: object\n",
      "     * bairro: object\n",
      "     * latitude: object\n",
      "     * longitude: float64\n",
      "     * tipo: object\n",
      "     * funcionamento: object\n",
      "   - Valores nulos: 0\n",
      "   - Memória: 0.28 MB\n",
      "\n",
      "[INFO] Equipamentos de Medição de Velocidade:\n",
      "   - Dimensões: 62 linhas x 7 colunas\n",
      "   - Colunas: ['_id', 'equipamento', 'tipo', 'logradouro', 'velocidade_via', 'latitude', 'longitude']\n",
      "   - Tipos de dados:\n",
      "     * _id: int64\n",
      "     * equipamento: object\n",
      "     * tipo: object\n",
      "     * logradouro: object\n",
      "     * velocidade_via: object\n",
      "     * latitude: float64\n",
      "     * longitude: float64\n",
      "   - Valores nulos: 0\n",
      "   - Memória: 0.02 MB\n",
      "\n",
      "[INFO] Fluxo de Veículos por Hora:\n",
      "   - Dimensões: 672 linhas x 28 colunas\n",
      "   - Colunas: ['equipamento', 'logradouro', 'horainicio', 'horafinal', 'quant000-009', 'porcentagem000-009', 'quant010-019', 'porcentagem010-019', 'quant020-029', 'porcentagem020-029', 'quant030-039', 'porcentagem030-039', 'quant040-049', 'porcentagem040-049', 'quant050-059', 'porcentagem050-059', 'quant060-069', 'porcentagem060-069', 'quant070-079', 'porcentagem070-079', 'quant080-089', 'porcentagem080-089', 'quant090-099', 'porcentagem090-099', 'quant100-200', 'porcentagem100-200', 'quanttotal', 'porcentagemtotal']\n",
      "   - Tipos de dados:\n",
      "     * equipamento: object\n",
      "     * logradouro: object\n",
      "     * horainicio: object\n",
      "     * horafinal: object\n",
      "     * quant000-009: int64\n",
      "     * porcentagem000-009: object\n",
      "     * quant010-019: int64\n",
      "     * porcentagem010-019: object\n",
      "     * quant020-029: int64\n",
      "     * porcentagem020-029: object\n",
      "     * quant030-039: int64\n",
      "     * porcentagem030-039: object\n",
      "     * quant040-049: int64\n",
      "     * porcentagem040-049: object\n",
      "     * quant050-059: int64\n",
      "     * porcentagem050-059: object\n",
      "     * quant060-069: int64\n",
      "     * porcentagem060-069: object\n",
      "     * quant070-079: int64\n",
      "     * porcentagem070-079: object\n",
      "     * quant080-089: int64\n",
      "     * porcentagem080-089: object\n",
      "     * quant090-099: int64\n",
      "     * porcentagem090-099: object\n",
      "     * quant100-200: int64\n",
      "     * porcentagem100-200: object\n",
      "     * quanttotal: int64\n",
      "     * porcentagemtotal: object\n",
      "   - Valores nulos: 0\n",
      "   - Memória: 0.67 MB\n",
      "\n",
      "[INFO] Fluxo e Velocidade 15min:\n",
      "   - Dimensões: 342796 linhas x 17 colunas\n",
      "   - Colunas: ['mes', 'equipamento', 'faixa', 'data', 'hora', 'minutos_intervalo', 'qtd_0a10km', 'qtd_11a20km', 'qtd_21a30km', 'qtd_31a40km', 'qtd_41a50km', 'qtd_51a60km', 'qtd_61a70km', 'qtd_71a80km', 'qtd_81a90km', 'qtd_91a100km', 'qtd_acimade100km']\n",
      "   - Tipos de dados:\n",
      "     * mes: object\n",
      "     * equipamento: int64\n",
      "     * faixa: object\n",
      "     * data: int64\n",
      "     * hora: object\n",
      "     * minutos_intervalo: int64\n",
      "     * qtd_0a10km: int64\n",
      "     * qtd_11a20km: int64\n",
      "     * qtd_21a30km: int64\n",
      "     * qtd_31a40km: int64\n",
      "     * qtd_41a50km: int64\n",
      "     * qtd_51a60km: int64\n",
      "     * qtd_61a70km: int64\n",
      "     * qtd_71a80km: int64\n",
      "     * qtd_81a90km: int64\n",
      "     * qtd_91a100km: int64\n",
      "     * qtd_acimade100km: float64\n",
      "   - Valores nulos: 342796\n",
      "   - Memória: 94.72 MB\n",
      "\n",
      "[INFO] Monitoramento CTTU:\n",
      "   - Dimensões: 54 linhas x 4 colunas\n",
      "   - Colunas: ['nome', 'endereco', 'longitude', 'latitude']\n",
      "   - Tipos de dados:\n",
      "     * nome: object\n",
      "     * endereco: object\n",
      "     * longitude: float64\n",
      "     * latitude: float64\n",
      "   - Valores nulos: 0\n",
      "   - Memória: 0.01 MB\n",
      "\n",
      "[INFO] Relatório Fluxo Janeiro:\n",
      "   - Dimensões: 283999 linhas x 18 colunas\n",
      "   - Colunas: ['ano', 'mes', 'equipamento', 'faixa', 'data', 'hour', 'minutos_intervalo', 'qtd_0a10km', 'qtd_11a20km', 'qtd_21a30km', 'qtd_31a40km', 'qtd_41a50km', 'qtd_51a60km', 'qtd_61a70km', 'qtd_71a80km', 'qtd_81a90km', 'qtd_91a100km', 'qtd_acimade100km']\n",
      "   - Tipos de dados:\n",
      "     * ano: int64\n",
      "     * mes: int64\n",
      "     * equipamento: object\n",
      "     * faixa: object\n",
      "     * data: object\n",
      "     * hour: int64\n",
      "     * minutos_intervalo: object\n",
      "     * qtd_0a10km: int64\n",
      "     * qtd_11a20km: int64\n",
      "     * qtd_21a30km: int64\n",
      "     * qtd_31a40km: int64\n",
      "     * qtd_41a50km: int64\n",
      "     * qtd_51a60km: int64\n",
      "     * qtd_61a70km: int64\n",
      "     * qtd_71a80km: int64\n",
      "     * qtd_81a90km: int64\n",
      "     * qtd_91a100km: float64\n",
      "     * qtd_acimade100km: int64\n",
      "   - Valores nulos: 283999\n",
      "   - Memória: 91.82 MB\n",
      "\n",
      "[INFO] Relatório Fluxo Fevereiro:\n",
      "   - Dimensões: 273529 linhas x 18 colunas\n",
      "   - Colunas: ['ano', 'mes', 'equipamento', 'faixa', 'data', 'hora', 'minutos_intervalo', 'qtd_0a10km', 'qtd_11a20km', 'qtd_21a30km', 'qtd_31a40km', 'qtd_41a50km', 'qtd_51a60km', 'qtd_61a70km', 'qtd_71a80km', 'qtd_81a90km', 'qtd_91a100km', 'qtd_acimade100km']\n",
      "   - Tipos de dados:\n",
      "     * ano: int64\n",
      "     * mes: int64\n",
      "     * equipamento: object\n",
      "     * faixa: object\n",
      "     * data: object\n",
      "     * hora: int64\n",
      "     * minutos_intervalo: object\n",
      "     * qtd_0a10km: int64\n",
      "     * qtd_11a20km: int64\n",
      "     * qtd_21a30km: int64\n",
      "     * qtd_31a40km: int64\n",
      "     * qtd_41a50km: int64\n",
      "     * qtd_51a60km: int64\n",
      "     * qtd_61a70km: int64\n",
      "     * qtd_71a80km: int64\n",
      "     * qtd_81a90km: int64\n",
      "     * qtd_91a100km: int64\n",
      "     * qtd_acimade100km: int64\n",
      "   - Valores nulos: 0\n",
      "   - Memória: 88.43 MB\n",
      "\n",
      "[INFO] Relatório Fluxo Março:\n",
      "   - Dimensões: 301067 linhas x 18 colunas\n",
      "   - Colunas: ['ano', 'mes', 'equipamento', 'faixa', 'data', 'hora', 'minutos_intervalo', 'qtd_0a10km', 'qtd_11a20km', 'qtd_21a30km', 'qtd_31a40km', 'qtd_41a50km', 'qtd_51a60km', 'qtd_61a70km', 'qtd_71a80km', 'qtd_81a90km', 'qtd_91a100km', 'qtd_acimade100km']\n",
      "   - Tipos de dados:\n",
      "     * ano: int64\n",
      "     * mes: int64\n",
      "     * equipamento: object\n",
      "     * faixa: object\n",
      "     * data: object\n",
      "     * hora: int64\n",
      "     * minutos_intervalo: object\n",
      "     * qtd_0a10km: int64\n",
      "     * qtd_11a20km: int64\n",
      "     * qtd_21a30km: int64\n",
      "     * qtd_31a40km: int64\n",
      "     * qtd_41a50km: int64\n",
      "     * qtd_51a60km: int64\n",
      "     * qtd_61a70km: int64\n",
      "     * qtd_71a80km: int64\n",
      "     * qtd_81a90km: int64\n",
      "     * qtd_91a100km: float64\n",
      "     * qtd_acimade100km: int64\n",
      "   - Valores nulos: 301067\n",
      "   - Memória: 97.33 MB\n",
      "\n",
      "[INFO] Relatório Fluxo Abril:\n",
      "   - Dimensões: 292669 linhas x 18 colunas\n",
      "   - Colunas: ['ano', 'mes', 'equipamento', 'faixa', 'data', 'hora', 'minutos_intervalo', 'qtd_0a10km', 'qtd_11a20km', 'qtd_21a30km', 'qtd_31a40km', 'qtd_41a50km', 'qtd_51a60km', 'qtd_61a70km', 'qtd_71a80km', 'qtd_81a90km', 'qtd_91a100km', 'qtd_acimade100km']\n",
      "   - Tipos de dados:\n",
      "     * ano: int64\n",
      "     * mes: int64\n",
      "     * equipamento: object\n",
      "     * faixa: object\n",
      "     * data: object\n",
      "     * hora: int64\n",
      "     * minutos_intervalo: object\n",
      "     * qtd_0a10km: int64\n",
      "     * qtd_11a20km: int64\n",
      "     * qtd_21a30km: int64\n",
      "     * qtd_31a40km: int64\n",
      "     * qtd_41a50km: int64\n",
      "     * qtd_51a60km: int64\n",
      "     * qtd_61a70km: int64\n",
      "     * qtd_71a80km: int64\n",
      "     * qtd_81a90km: int64\n",
      "     * qtd_91a100km: float64\n",
      "     * qtd_acimade100km: int64\n",
      "   - Valores nulos: 292669\n",
      "   - Memória: 94.62 MB\n",
      "\n",
      "[INFO] Relatório Fluxo Maio:\n",
      "   - Dimensões: 300932 linhas x 18 colunas\n",
      "   - Colunas: ['ano', 'mes', 'equipamento', 'faixa', 'data', 'hora', 'minutos_intervalo', 'qtd_0a10km', 'qtd_11a20km', 'qtd_21a30km', 'qtd_31a40km', 'qtd_41a50km', 'qtd_51a60km', 'qtd_61a70km', 'qtd_71a80km', 'qtd_81a90km', 'qtd_91a100km', 'qtd_acimade100km']\n",
      "   - Tipos de dados:\n",
      "     * ano: int64\n",
      "     * mes: int64\n",
      "     * equipamento: float64\n",
      "     * faixa: object\n",
      "     * data: object\n",
      "     * hora: object\n",
      "     * minutos_intervalo: float64\n",
      "     * qtd_0a10km: object\n",
      "     * qtd_11a20km: float64\n",
      "     * qtd_21a30km: float64\n",
      "     * qtd_31a40km: float64\n",
      "     * qtd_41a50km: float64\n",
      "     * qtd_51a60km: float64\n",
      "     * qtd_61a70km: float64\n",
      "     * qtd_71a80km: float64\n",
      "     * qtd_81a90km: float64\n",
      "     * qtd_91a100km: float64\n",
      "     * qtd_acimade100km: float64\n",
      "   - Valores nulos: 601877\n",
      "   - Memória: 97.86 MB\n",
      "\n",
      "[INFO] Relatório Fluxo Junho:\n",
      "   - Dimensões: 289577 linhas x 18 colunas\n",
      "   - Colunas: ['ano', 'mes', 'equipamento', 'faixa', 'data', 'hora', 'minutos_intervalo', 'qtd_0a10km', 'qtd_11a20km', 'qtd_21a30km', 'qtd_31a40km', 'qtd_41a50km', 'qtd_51a60km', 'qtd_61a70km', 'qtd_71a80km', 'qtd_81a90km', 'qtd_91a100km', 'qtd_acimade100km']\n",
      "   - Tipos de dados:\n",
      "     * ano: int64\n",
      "     * mes: int64\n",
      "     * equipamento: object\n",
      "     * faixa: object\n",
      "     * data: object\n",
      "     * hora: int64\n",
      "     * minutos_intervalo: object\n",
      "     * qtd_0a10km: int64\n",
      "     * qtd_11a20km: int64\n",
      "     * qtd_21a30km: int64\n",
      "     * qtd_31a40km: int64\n",
      "     * qtd_41a50km: int64\n",
      "     * qtd_51a60km: int64\n",
      "     * qtd_61a70km: int64\n",
      "     * qtd_71a80km: int64\n",
      "     * qtd_81a90km: int64\n",
      "     * qtd_91a100km: int64\n",
      "     * qtd_acimade100km: int64\n",
      "   - Valores nulos: 0\n",
      "   - Memória: 93.62 MB\n",
      "\n",
      "[INFO] Relatório Fluxo Julho:\n",
      "   - Dimensões: 297149 linhas x 18 colunas\n",
      "   - Colunas: ['ano', 'mes', 'equipamento', 'faixa', 'data', 'hora', 'minutos_intervalo', 'qtd_0a10km', 'qtd_11a20km', 'qtd_21a30km', 'qtd_31a40km', 'qtd_41a50km', 'qtd_51a60km', 'qtd_61a70km', 'qtd_71a80km', 'qtd_81a90km', 'qtd_91a100km', 'qtd_acimade100km']\n",
      "   - Tipos de dados:\n",
      "     * ano: int64\n",
      "     * mes: int64\n",
      "     * equipamento: object\n",
      "     * faixa: object\n",
      "     * data: object\n",
      "     * hora: int64\n",
      "     * minutos_intervalo: object\n",
      "     * qtd_0a10km: int64\n",
      "     * qtd_11a20km: int64\n",
      "     * qtd_21a30km: int64\n",
      "     * qtd_31a40km: int64\n",
      "     * qtd_41a50km: int64\n",
      "     * qtd_51a60km: int64\n",
      "     * qtd_61a70km: int64\n",
      "     * qtd_71a80km: int64\n",
      "     * qtd_81a90km: int64\n",
      "     * qtd_91a100km: float64\n",
      "     * qtd_acimade100km: int64\n",
      "   - Valores nulos: 297149\n",
      "   - Memória: 96.07 MB\n",
      "\n",
      "[INFO] Relatório Fluxo Agosto:\n",
      "   - Dimensões: 298228 linhas x 18 colunas\n",
      "   - Colunas: ['ano', 'mes', 'equipamento', 'faixa', 'data', 'hora', 'minutos_intervalo', 'qtd_0a10km', 'qtd_11a20km', 'qtd_21a30km', 'qtd_31a40km', 'qtd_41a50km', 'qtd_51a60km', 'qtd_61a70km', 'qtd_71a80km', 'qtd_81a90km', 'qtd_91a100km', 'qtd_acimade100km']\n",
      "   - Tipos de dados:\n",
      "     * ano: int64\n",
      "     * mes: int64\n",
      "     * equipamento: object\n",
      "     * faixa: object\n",
      "     * data: object\n",
      "     * hora: int64\n",
      "     * minutos_intervalo: object\n",
      "     * qtd_0a10km: int64\n",
      "     * qtd_11a20km: int64\n",
      "     * qtd_21a30km: int64\n",
      "     * qtd_31a40km: int64\n",
      "     * qtd_41a50km: int64\n",
      "     * qtd_51a60km: int64\n",
      "     * qtd_61a70km: int64\n",
      "     * qtd_71a80km: int64\n",
      "     * qtd_81a90km: int64\n",
      "     * qtd_91a100km: int64\n",
      "     * qtd_acimade100km: int64\n",
      "   - Valores nulos: 0\n",
      "   - Memória: 96.42 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Análise exploratória inicial dos datasets\n",
    "print(\"=== ANÁLISE EXPLORATÓRIA DOS DATASETS ===\\n\")\n",
    "\n",
    "datasets = {\n",
    "    \"Semáforos\": semaforos_df,\n",
    "    \"Equipamentos de Medição de Velocidade\": equip_med_vel_df,\n",
    "    \"Fluxo de Veículos por Hora\": fluxo_veiculos_hora_df,\n",
    "    \"Fluxo e Velocidade 15min\": fluxo_velocidade_15min_df,\n",
    "    \"Monitoramento CTTU\": monitoramento_cttu_df,\n",
    "    \"Relatório Fluxo Janeiro\": relatorio_fluxo_jan_df,\n",
    "    \"Relatório Fluxo Fevereiro\": relatorio_fluxo_fev_df,\n",
    "    \"Relatório Fluxo Março\": relatorio_fluxo_mar_df,\n",
    "    \"Relatório Fluxo Abril\": relatorio_fluxo_abr_df,\n",
    "    \"Relatório Fluxo Maio\": relatorio_fluxo_mai_df,\n",
    "    \"Relatório Fluxo Junho\": relatorio_fluxo_jun_df,\n",
    "    \"Relatório Fluxo Julho\": relatorio_fluxo_jul_df,\n",
    "    \"Relatório Fluxo Agosto\": relatorio_fluxo_ago_df\n",
    "}\n",
    "\n",
    "for nome, df in datasets.items():\n",
    "    print(f\"[INFO] {nome}:\")\n",
    "    if df is not None:\n",
    "        print(f\"   - Dimensões: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
    "        print(f\"   - Colunas: {list(df.columns)}\")\n",
    "        print(f\"   - Tipos de dados:\")\n",
    "        for col in df.columns:\n",
    "            print(f\"     * {col}: {df[col].dtype}\")\n",
    "        print(f\"   - Valores nulos: {df.isnull().sum().sum()}\")\n",
    "        print(f\"   - Memória: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    else:\n",
    "        print(\"   - Status: Não disponível\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b48acdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO LIMPEZA DOS DADOS ===\n",
      "\n",
      "[PROCESSANDO] Limpando dados de semaforos...\n",
      "   [OK] Semaforos limpos: 712 registros\n",
      "   [OK] Valores nulos: 1\n"
     ]
    }
   ],
   "source": [
    "# LIMPEZA E PADRONIZAÇÃO DOS DADOS\n",
    "\n",
    "print(\"=== INICIANDO LIMPEZA DOS DADOS ===\\n\")\n",
    "\n",
    "# 1. LIMPEZA DOS SEMÁFOROS\n",
    "if semaforos_df is not None:\n",
    "    print(\"[PROCESSANDO] Limpando dados de semaforos...\")\n",
    "    semaforos_clean = semaforos_df.copy()\n",
    "\n",
    "    # Padronizar coordenadas\n",
    "    semaforos_clean['latitude'] = pd.to_numeric(semaforos_clean['latitude'], errors='coerce')\n",
    "    semaforos_clean['longitude'] = pd.to_numeric(semaforos_clean['longitude'], errors='coerce')\n",
    "\n",
    "    # Limpar strings (apenas se forem do tipo object/string)\n",
    "    if 'localizacao1' in semaforos_clean.columns and semaforos_clean['localizacao1'].dtype == 'object':\n",
    "        semaforos_clean['localizacao1'] = semaforos_clean['localizacao1'].astype(str).str.strip()\n",
    "    if 'localizacao2' in semaforos_clean.columns and semaforos_clean['localizacao2'].dtype == 'object':\n",
    "        semaforos_clean['localizacao2'] = semaforos_clean['localizacao2'].astype(str).str.strip()\n",
    "    if 'bairro' in semaforos_clean.columns and semaforos_clean['bairro'].dtype == 'object':\n",
    "        semaforos_clean['bairro'] = semaforos_clean['bairro'].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Adicionar coluna de identificação única\n",
    "    semaforos_clean['id_semaforo'] = semaforos_clean['_id']\n",
    "\n",
    "    print(f\"   [OK] Semaforos limpos: {semaforos_clean.shape[0]} registros\")\n",
    "    print(f\"   [OK] Valores nulos: {semaforos_clean.isnull().sum().sum()}\")\n",
    "else:\n",
    "    print(\"[AVISO] Semaforos nao disponivel - pulando limpeza\")\n",
    "    semaforos_clean = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "920f105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIGURANDO] Limpando dados de equipamentos de medição de velocidade...\n",
      "   Colunas disponíveis: ['_id', 'equipamento', 'tipo', 'logradouro', 'velocidade_via', 'latitude', 'longitude']\n",
      "   [OK] Equipamentos de medição limpos: 62 registros\n",
      "   [OK] Valores nulos: 0\n"
     ]
    }
   ],
   "source": [
    "# 2. LIMPEZA DOS EQUIPAMENTOS DE MEDIÇÃO DE VELOCIDADE\n",
    "if equip_med_vel_df is not None:\n",
    "    print(\"[CONFIGURANDO] Limpando dados de equipamentos de medição de velocidade...\")\n",
    "    equip_med_vel_clean = equip_med_vel_df.copy()\n",
    "    \n",
    "    # Mostrar colunas disponíveis para debug\n",
    "    print(f\"   Colunas disponíveis: {list(equip_med_vel_clean.columns)}\")\n",
    "\n",
    "    # Padronizar coordenadas\n",
    "    equip_med_vel_clean['latitude'] = pd.to_numeric(equip_med_vel_clean['latitude'], errors='coerce')\n",
    "    equip_med_vel_clean['longitude'] = pd.to_numeric(equip_med_vel_clean['longitude'], errors='coerce')\n",
    "\n",
    "    # Padronizar valores numéricos (apenas se as colunas existirem)\n",
    "    if 'faixas_fiscalizadas' in equip_med_vel_clean.columns:\n",
    "        equip_med_vel_clean['faixas_fiscalizadas'] = pd.to_numeric(equip_med_vel_clean['faixas_fiscalizadas'], errors='coerce')\n",
    "    if 'velocidade_fiscalizada' in equip_med_vel_clean.columns:\n",
    "        equip_med_vel_clean['velocidade_fiscalizada'] = pd.to_numeric(equip_med_vel_clean['velocidade_fiscalizada'], errors='coerce')\n",
    "    if 'vmd' in equip_med_vel_clean.columns:\n",
    "        equip_med_vel_clean['vmd'] = pd.to_numeric(equip_med_vel_clean['vmd'], errors='coerce')\n",
    "\n",
    "    # Limpar strings (apenas se as colunas existirem e forem do tipo object/string)\n",
    "    if 'local_instalacao' in equip_med_vel_clean.columns and equip_med_vel_clean['local_instalacao'].dtype == 'object':\n",
    "        equip_med_vel_clean['local_instalacao'] = equip_med_vel_clean['local_instalacao'].astype(str).str.strip()\n",
    "    if 'sentido_fiscalizacao' in equip_med_vel_clean.columns and equip_med_vel_clean['sentido_fiscalizacao'].dtype == 'object':\n",
    "        equip_med_vel_clean['sentido_fiscalizacao'] = equip_med_vel_clean['sentido_fiscalizacao'].astype(str).str.strip()\n",
    "    if 'periodo_vmd' in equip_med_vel_clean.columns and equip_med_vel_clean['periodo_vmd'].dtype == 'object':\n",
    "        equip_med_vel_clean['periodo_vmd'] = equip_med_vel_clean['periodo_vmd'].astype(str).str.strip()\n",
    "\n",
    "    print(f\"   [OK] Equipamentos de medição limpos: {equip_med_vel_clean.shape[0]} registros\")\n",
    "    print(f\"   [OK] Valores nulos: {equip_med_vel_clean.isnull().sum().sum()}\")\n",
    "else:\n",
    "    print(\"[ATENCAO]  Equipamentos de medição não disponível - pulando limpeza\")\n",
    "    equip_med_vel_clean = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a637dbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIGURANDO] Limpando dados de fluxo de veículos por hora...\n",
      "   [OK] Fluxo de veículos por hora limpo: 672 registros\n",
      "   [OK] Valores nulos: 0\n"
     ]
    }
   ],
   "source": [
    "# 3. LIMPEZA DO FLUXO DE VEÍCULOS POR HORA\n",
    "if fluxo_veiculos_hora_df is not None:\n",
    "    print(\"[CONFIGURANDO] Limpando dados de fluxo de veículos por hora...\")\n",
    "    fluxo_veiculos_hora_clean = fluxo_veiculos_hora_df.copy()\n",
    "\n",
    "    # Converter colunas de quantidade para numérico\n",
    "    quantidade_cols = [col for col in fluxo_veiculos_hora_clean.columns if col.startswith('quant')]\n",
    "    for col in quantidade_cols:\n",
    "        fluxo_veiculos_hora_clean[col] = pd.to_numeric(fluxo_veiculos_hora_clean[col], errors='coerce')\n",
    "\n",
    "    # Converter colunas de porcentagem para numérico (substituir vírgula por ponto)\n",
    "    porcentagem_cols = [col for col in fluxo_veiculos_hora_clean.columns if col.startswith('porcentagem')]\n",
    "    for col in porcentagem_cols:\n",
    "        fluxo_veiculos_hora_clean[col] = fluxo_veiculos_hora_clean[col].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "    # Limpar strings (apenas se forem do tipo object/string)\n",
    "    if 'equipamento' in fluxo_veiculos_hora_clean.columns and fluxo_veiculos_hora_clean['equipamento'].dtype == 'object':\n",
    "        fluxo_veiculos_hora_clean['equipamento'] = fluxo_veiculos_hora_clean['equipamento'].astype(str).str.strip()\n",
    "    if 'logradouro' in fluxo_veiculos_hora_clean.columns and fluxo_veiculos_hora_clean['logradouro'].dtype == 'object':\n",
    "        fluxo_veiculos_hora_clean['logradouro'] = fluxo_veiculos_hora_clean['logradouro'].astype(str).str.strip()\n",
    "\n",
    "    # Converter horários para datetime\n",
    "    fluxo_veiculos_hora_clean['horainicio'] = pd.to_datetime(fluxo_veiculos_hora_clean['horainicio'], format='%H:%M', errors='coerce')\n",
    "    fluxo_veiculos_hora_clean['horafinal'] = pd.to_datetime(fluxo_veiculos_hora_clean['horafinal'], format='%H:%M', errors='coerce')\n",
    "\n",
    "    print(f\"   [OK] Fluxo de veículos por hora limpo: {fluxo_veiculos_hora_clean.shape[0]} registros\")\n",
    "    print(f\"   [OK] Valores nulos: {fluxo_veiculos_hora_clean.isnull().sum().sum()}\")\n",
    "else:\n",
    "    print(\"[ATENCAO]  Fluxo de veículos por hora não disponível - pulando limpeza\")\n",
    "    fluxo_veiculos_hora_clean = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20c5aa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIGURANDO] Limpando dados de fluxo e velocidade em 15 minutos...\n",
      "   [ATUALIZANDO] Corrigindo estrutura das colunas...\n",
      "   Colunas corrigidas: ['equipamento', 'faixa', 'data', 'hora', 'minutos_intervalo', 'qtd_0a10km', 'qtd_11a20km', 'qtd_21a30km', 'qtd_31a40km', 'qtd_41a50km', 'qtd_51a60km', 'qtd_61a70km', 'qtd_71a80km', 'qtd_81a90km', 'qtd_91a100km', 'qtd_acimade100km', 'mes']\n",
      "   [OK] Fluxo e velocidade 15min limpo: 342796 registros\n",
      "   [OK] Valores nulos: 0\n"
     ]
    }
   ],
   "source": [
    "# 4. LIMPEZA DO FLUXO E VELOCIDADE EM 15 MINUTOS\n",
    "if fluxo_velocidade_15min_df is not None:\n",
    "    print(\"[CONFIGURANDO] Limpando dados de fluxo e velocidade em 15 minutos...\")\n",
    "    fluxo_velocidade_15min_clean = fluxo_velocidade_15min_df.copy()\n",
    "    \n",
    "    # CORREÇÃO: O arquivo tem colunas trocadas no cabeçalho\n",
    "    # Renomear colunas para corrigir a estrutura\n",
    "    print(\"   [ATUALIZANDO] Corrigindo estrutura das colunas...\")\n",
    "    \n",
    "    # Primeiro, remover a coluna minutos_intervalo original se existir (para evitar duplicata após renomeação)\n",
    "    if 'minutos_intervalo' in fluxo_velocidade_15min_clean.columns:\n",
    "        fluxo_velocidade_15min_clean = fluxo_velocidade_15min_clean.drop('minutos_intervalo', axis=1)\n",
    "    fluxo_velocidade_15min_clean = fluxo_velocidade_15min_clean.rename(columns={\n",
    "        'mes': 'equipamento',           # mes contém códigos de equipamento\n",
    "        'equipamento': 'faixa',         # equipamento contém números de faixa\n",
    "        'faixa': 'data',                # faixa contém datas\n",
    "        'data': 'hora',                 # data contém horas\n",
    "        'hora': 'minutos_intervalo'     # hora contém intervalos de minutos\n",
    "    })\n",
    "    \n",
    "    # Adicionar coluna mes correta (extrair do equipamento ou usar valor padrão)\n",
    "    fluxo_velocidade_15min_clean['mes'] = 1  # Janeiro 2025\n",
    "    \n",
    "    # Garantir que não há colunas duplicadas (remover duplicatas por nome)\n",
    "    fluxo_velocidade_15min_clean = fluxo_velocidade_15min_clean.loc[:, ~fluxo_velocidade_15min_clean.columns.duplicated()]\n",
    "    \n",
    "    # Remover coluna duplicada se existir\n",
    "    if 'minutos_intervalo.1' in fluxo_velocidade_15min_clean.columns:\n",
    "        fluxo_velocidade_15min_clean = fluxo_velocidade_15min_clean.drop('minutos_intervalo.1', axis=1)\n",
    "        print(\"   [ATUALIZANDO] Coluna duplicada removida\")\n",
    "    \n",
    "    # Mostrar colunas corrigidas\n",
    "    print(f\"   Colunas corrigidas: {list(fluxo_velocidade_15min_clean.columns)}\")\n",
    "    \n",
    "    # Converter colunas de quantidade para numérico\n",
    "    quantidade_cols = [col for col in fluxo_velocidade_15min_clean.columns if col.startswith('qtd_')]\n",
    "    for col in quantidade_cols:\n",
    "        fluxo_velocidade_15min_clean[col] = pd.to_numeric(fluxo_velocidade_15min_clean[col], errors='coerce')\n",
    "    \n",
    "    # Preencher valores NaN com 0 nas colunas de quantidade\n",
    "    for col in quantidade_cols:\n",
    "        fluxo_velocidade_15min_clean[col] = fluxo_velocidade_15min_clean[col].fillna(0)\n",
    "\n",
    "    # Converter data para datetime\n",
    "    if 'data' in fluxo_velocidade_15min_clean.columns:\n",
    "        fluxo_velocidade_15min_clean['data'] = pd.to_datetime(fluxo_velocidade_15min_clean['data'], errors='coerce')\n",
    "\n",
    "    # Limpar strings (apenas se forem do tipo object/string)\n",
    "    if 'equipamento' in fluxo_velocidade_15min_clean.columns and fluxo_velocidade_15min_clean['equipamento'].dtype == 'object':\n",
    "        fluxo_velocidade_15min_clean['equipamento'] = fluxo_velocidade_15min_clean['equipamento'].astype(str).str.strip()\n",
    "    if 'faixa' in fluxo_velocidade_15min_clean.columns and fluxo_velocidade_15min_clean['faixa'].dtype == 'object':\n",
    "        fluxo_velocidade_15min_clean['faixa'] = fluxo_velocidade_15min_clean['faixa'].astype(str).str.strip()\n",
    "\n",
    "    # Converter hora para int\n",
    "    if 'hora' in fluxo_velocidade_15min_clean.columns:\n",
    "        fluxo_velocidade_15min_clean['hora'] = pd.to_numeric(fluxo_velocidade_15min_clean['hora'], errors='coerce')\n",
    "\n",
    "    print(f\"   [OK] Fluxo e velocidade 15min limpo: {fluxo_velocidade_15min_clean.shape[0]} registros\")\n",
    "    print(f\"   [OK] Valores nulos: {fluxo_velocidade_15min_clean.isnull().sum().sum()}\")\n",
    "else:\n",
    "    print(\"[ATENCAO]  Fluxo e velocidade 15min não disponível - pulando limpeza\")\n",
    "    fluxo_velocidade_15min_clean = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "730eb8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIGURANDO] Limpando dados dos relatórios de fluxo...\n",
      "   [OK] Relatório Janeiro limpo: 283999 registros\n",
      "   [OK] Relatório Fevereiro limpo: 273529 registros\n",
      "   [OK] Relatório Março limpo: 301067 registros\n",
      "   [OK] Relatório Abril limpo: 292669 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\AppData\\Local\\Temp\\ipykernel_14176\\1397489317.py:92: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  relatorio_fluxo_mai_clean['data'] = pd.to_datetime(relatorio_fluxo_mai_clean['data'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [OK] Relatório Maio limpo: 300932 registros\n",
      "   [OK] Relatório Junho limpo: 289577 registros\n",
      "   [OK] Relatório Julho limpo: 297149 registros\n",
      "   [OK] Relatório Agosto limpo: 298228 registros\n"
     ]
    }
   ],
   "source": [
    "# 5. LIMPEZA DOS RELATÓRIOS DE FLUXO (AGOSTO E FEVEREIRO)\n",
    "print(\"[CONFIGURANDO] Limpando dados dos relatórios de fluxo...\")\n",
    "\n",
    "# Limpeza do relatório de Janeiro\n",
    "if relatorio_fluxo_jan_df is not None:\n",
    "    relatorio_fluxo_jan_clean = relatorio_fluxo_jan_df.copy()\n",
    "    quantidade_cols = [col for col in relatorio_fluxo_jan_clean.columns if col.startswith('qtd_')]\n",
    "    for col in quantidade_cols:\n",
    "        relatorio_fluxo_jan_clean[col] = pd.to_numeric(relatorio_fluxo_jan_clean[col], errors='coerce')\n",
    "\n",
    "    if 'data' in relatorio_fluxo_jan_clean.columns:\n",
    "        relatorio_fluxo_jan_clean['data'] = pd.to_datetime(relatorio_fluxo_jan_clean['data'], errors='coerce')\n",
    "    if 'equipamento' in relatorio_fluxo_jan_clean.columns and relatorio_fluxo_jan_clean['equipamento'].dtype == 'object':\n",
    "        relatorio_fluxo_jan_clean['equipamento'] = relatorio_fluxo_jan_clean['equipamento'].astype(str).str.strip()\n",
    "    if 'faixa' in relatorio_fluxo_jan_clean.columns and relatorio_fluxo_jan_clean['faixa'].dtype == 'object':\n",
    "        relatorio_fluxo_jan_clean['faixa'] = relatorio_fluxo_jan_clean['faixa'].astype(str).str.strip()\n",
    "    if 'hora' in relatorio_fluxo_jan_clean.columns:\n",
    "        relatorio_fluxo_jan_clean['hora'] = pd.to_numeric(relatorio_fluxo_jan_clean['hora'], errors='coerce')\n",
    "    print(f\"   [OK] Relatório Janeiro limpo: {relatorio_fluxo_jan_clean.shape[0]} registros\")\n",
    "else:\n",
    "    relatorio_fluxo_jan_clean = None\n",
    "    print(\"   [ATENCAO]  Relatório Janeiro não disponível\")\n",
    "\n",
    "# Limpeza do relatório de Fevereiro\n",
    "if relatorio_fluxo_fev_df is not None:\n",
    "    relatorio_fluxo_fev_clean = relatorio_fluxo_fev_df.copy()\n",
    "    quantidade_cols = [col for col in relatorio_fluxo_fev_clean.columns if col.startswith('qtd_')]\n",
    "    for col in quantidade_cols:\n",
    "        relatorio_fluxo_fev_clean[col] = pd.to_numeric(relatorio_fluxo_fev_clean[col], errors='coerce')\n",
    "\n",
    "    if 'data' in relatorio_fluxo_fev_clean.columns:\n",
    "        relatorio_fluxo_fev_clean['data'] = pd.to_datetime(relatorio_fluxo_fev_clean['data'], errors='coerce')\n",
    "    if 'equipamento' in relatorio_fluxo_fev_clean.columns and relatorio_fluxo_fev_clean['equipamento'].dtype == 'object':\n",
    "        relatorio_fluxo_fev_clean['equipamento'] = relatorio_fluxo_fev_clean['equipamento'].astype(str).str.strip()\n",
    "    if 'faixa' in relatorio_fluxo_fev_clean.columns and relatorio_fluxo_fev_clean['faixa'].dtype == 'object':\n",
    "        relatorio_fluxo_fev_clean['faixa'] = relatorio_fluxo_fev_clean['faixa'].astype(str).str.strip()\n",
    "    if 'hora' in relatorio_fluxo_fev_clean.columns:\n",
    "        relatorio_fluxo_fev_clean['hora'] = pd.to_numeric(relatorio_fluxo_fev_clean['hora'], errors='coerce')\n",
    "    print(f\"   [OK] Relatório Fevereiro limpo: {relatorio_fluxo_fev_clean.shape[0]} registros\")\n",
    "else:\n",
    "    relatorio_fluxo_fev_clean = None\n",
    "    print(\"   [ATENCAO]  Relatório Fevereiro não disponível\")\n",
    "\n",
    "# Limpeza do relatório de Março\n",
    "if relatorio_fluxo_mar_df is not None:\n",
    "    relatorio_fluxo_mar_clean = relatorio_fluxo_mar_df.copy()\n",
    "    quantidade_cols = [col for col in relatorio_fluxo_mar_clean.columns if col.startswith('qtd_')]\n",
    "    for col in quantidade_cols:\n",
    "        relatorio_fluxo_mar_clean[col] = pd.to_numeric(relatorio_fluxo_mar_clean[col], errors='coerce')\n",
    "\n",
    "    if 'data' in relatorio_fluxo_mar_clean.columns:\n",
    "        relatorio_fluxo_mar_clean['data'] = pd.to_datetime(relatorio_fluxo_mar_clean['data'], errors='coerce')\n",
    "    if 'equipamento' in relatorio_fluxo_mar_clean.columns and relatorio_fluxo_mar_clean['equipamento'].dtype == 'object':\n",
    "        relatorio_fluxo_mar_clean['equipamento'] = relatorio_fluxo_mar_clean['equipamento'].astype(str).str.strip()\n",
    "    if 'faixa' in relatorio_fluxo_mar_clean.columns and relatorio_fluxo_mar_clean['faixa'].dtype == 'object':\n",
    "        relatorio_fluxo_mar_clean['faixa'] = relatorio_fluxo_mar_clean['faixa'].astype(str).str.strip()\n",
    "    if 'hora' in relatorio_fluxo_mar_clean.columns:\n",
    "        relatorio_fluxo_mar_clean['hora'] = pd.to_numeric(relatorio_fluxo_mar_clean['hora'], errors='coerce')\n",
    "    print(f\"   [OK] Relatório Março limpo: {relatorio_fluxo_mar_clean.shape[0]} registros\")\n",
    "else:\n",
    "    relatorio_fluxo_mar_clean = None\n",
    "    print(\"   [ATENCAO]  Relatório Março não disponível\")\n",
    "\n",
    "# Limpeza do relatório de Abril\n",
    "if relatorio_fluxo_abr_df is not None:\n",
    "    relatorio_fluxo_abr_clean = relatorio_fluxo_abr_df.copy()\n",
    "    quantidade_cols = [col for col in relatorio_fluxo_abr_clean.columns if col.startswith('qtd_')]\n",
    "    for col in quantidade_cols:\n",
    "        relatorio_fluxo_abr_clean[col] = pd.to_numeric(relatorio_fluxo_abr_clean[col], errors='coerce')\n",
    "\n",
    "    if 'data' in relatorio_fluxo_abr_clean.columns:\n",
    "        relatorio_fluxo_abr_clean['data'] = pd.to_datetime(relatorio_fluxo_abr_clean['data'], errors='coerce')\n",
    "    if 'equipamento' in relatorio_fluxo_abr_clean.columns and relatorio_fluxo_abr_clean['equipamento'].dtype == 'object':\n",
    "        relatorio_fluxo_abr_clean['equipamento'] = relatorio_fluxo_abr_clean['equipamento'].astype(str).str.strip()\n",
    "    if 'faixa' in relatorio_fluxo_abr_clean.columns and relatorio_fluxo_abr_clean['faixa'].dtype == 'object':\n",
    "        relatorio_fluxo_abr_clean['faixa'] = relatorio_fluxo_abr_clean['faixa'].astype(str).str.strip()\n",
    "    if 'hora' in relatorio_fluxo_abr_clean.columns:\n",
    "        relatorio_fluxo_abr_clean['hora'] = pd.to_numeric(relatorio_fluxo_abr_clean['hora'], errors='coerce')\n",
    "    print(f\"   [OK] Relatório Abril limpo: {relatorio_fluxo_abr_clean.shape[0]} registros\")\n",
    "else:\n",
    "    relatorio_fluxo_abr_clean = None\n",
    "    print(\"   [ATENCAO]  Relatório Abril não disponível\")\n",
    "\n",
    "# Limpeza do relatório de Maio\n",
    "if relatorio_fluxo_mai_df is not None:\n",
    "    relatorio_fluxo_mai_clean = relatorio_fluxo_mai_df.copy()\n",
    "    quantidade_cols = [col for col in relatorio_fluxo_mai_clean.columns if col.startswith('qtd_')]\n",
    "    for col in quantidade_cols:\n",
    "        relatorio_fluxo_mai_clean[col] = pd.to_numeric(relatorio_fluxo_mai_clean[col], errors='coerce')\n",
    "\n",
    "    if 'data' in relatorio_fluxo_mai_clean.columns:\n",
    "        relatorio_fluxo_mai_clean['data'] = pd.to_datetime(relatorio_fluxo_mai_clean['data'], errors='coerce')\n",
    "    if 'equipamento' in relatorio_fluxo_mai_clean.columns and relatorio_fluxo_mai_clean['equipamento'].dtype == 'object':\n",
    "        relatorio_fluxo_mai_clean['equipamento'] = relatorio_fluxo_mai_clean['equipamento'].astype(str).str.strip()\n",
    "    if 'faixa' in relatorio_fluxo_mai_clean.columns and relatorio_fluxo_mai_clean['faixa'].dtype == 'object':\n",
    "        relatorio_fluxo_mai_clean['faixa'] = relatorio_fluxo_mai_clean['faixa'].astype(str).str.strip()\n",
    "    if 'hora' in relatorio_fluxo_mai_clean.columns:\n",
    "        relatorio_fluxo_mai_clean['hora'] = pd.to_numeric(relatorio_fluxo_mai_clean['hora'], errors='coerce')\n",
    "    print(f\"   [OK] Relatório Maio limpo: {relatorio_fluxo_mai_clean.shape[0]} registros\")\n",
    "else:\n",
    "    relatorio_fluxo_mai_clean = None\n",
    "    print(\"   [ATENCAO]  Relatório Maio não disponível\")\n",
    "\n",
    "# Limpeza do relatório de Junho\n",
    "if relatorio_fluxo_jun_df is not None:\n",
    "    relatorio_fluxo_jun_clean = relatorio_fluxo_jun_df.copy()\n",
    "    quantidade_cols = [col for col in relatorio_fluxo_jun_clean.columns if col.startswith('qtd_')]\n",
    "    for col in quantidade_cols:\n",
    "        relatorio_fluxo_jun_clean[col] = pd.to_numeric(relatorio_fluxo_jun_clean[col], errors='coerce')\n",
    "\n",
    "    if 'data' in relatorio_fluxo_jun_clean.columns:\n",
    "        relatorio_fluxo_jun_clean['data'] = pd.to_datetime(relatorio_fluxo_jun_clean['data'], errors='coerce')\n",
    "    if 'equipamento' in relatorio_fluxo_jun_clean.columns and relatorio_fluxo_jun_clean['equipamento'].dtype == 'object':\n",
    "        relatorio_fluxo_jun_clean['equipamento'] = relatorio_fluxo_jun_clean['equipamento'].astype(str).str.strip()\n",
    "    if 'faixa' in relatorio_fluxo_jun_clean.columns and relatorio_fluxo_jun_clean['faixa'].dtype == 'object':\n",
    "        relatorio_fluxo_jun_clean['faixa'] = relatorio_fluxo_jun_clean['faixa'].astype(str).str.strip()\n",
    "    if 'hora' in relatorio_fluxo_jun_clean.columns:\n",
    "        relatorio_fluxo_jun_clean['hora'] = pd.to_numeric(relatorio_fluxo_jun_clean['hora'], errors='coerce')\n",
    "    print(f\"   [OK] Relatório Junho limpo: {relatorio_fluxo_jun_clean.shape[0]} registros\")\n",
    "else:\n",
    "    relatorio_fluxo_jun_clean = None\n",
    "    print(\"   [ATENCAO]  Relatório Junho não disponível\")\n",
    "\n",
    "# Limpeza do relatório de Julho\n",
    "if relatorio_fluxo_jul_df is not None:\n",
    "    relatorio_fluxo_jul_clean = relatorio_fluxo_jul_df.copy()\n",
    "    quantidade_cols = [col for col in relatorio_fluxo_jul_clean.columns if col.startswith('qtd_')]\n",
    "    for col in quantidade_cols:\n",
    "        relatorio_fluxo_jul_clean[col] = pd.to_numeric(relatorio_fluxo_jul_clean[col], errors='coerce')\n",
    "\n",
    "    if 'data' in relatorio_fluxo_jul_clean.columns:\n",
    "        relatorio_fluxo_jul_clean['data'] = pd.to_datetime(relatorio_fluxo_jul_clean['data'], errors='coerce')\n",
    "    if 'equipamento' in relatorio_fluxo_jul_clean.columns and relatorio_fluxo_jul_clean['equipamento'].dtype == 'object':\n",
    "        relatorio_fluxo_jul_clean['equipamento'] = relatorio_fluxo_jul_clean['equipamento'].astype(str).str.strip()\n",
    "    if 'faixa' in relatorio_fluxo_jul_clean.columns and relatorio_fluxo_jul_clean['faixa'].dtype == 'object':\n",
    "        relatorio_fluxo_jul_clean['faixa'] = relatorio_fluxo_jul_clean['faixa'].astype(str).str.strip()\n",
    "    if 'hora' in relatorio_fluxo_jul_clean.columns:\n",
    "        relatorio_fluxo_jul_clean['hora'] = pd.to_numeric(relatorio_fluxo_jul_clean['hora'], errors='coerce')\n",
    "    print(f\"   [OK] Relatório Julho limpo: {relatorio_fluxo_jul_clean.shape[0]} registros\")\n",
    "else:\n",
    "    relatorio_fluxo_jul_clean = None\n",
    "    print(\"   [ATENCAO]  Relatório Julho não disponível\")\n",
    "\n",
    "# Limpeza do relatório de Agosto\n",
    "if relatorio_fluxo_ago_df is not None:\n",
    "    relatorio_fluxo_ago_clean = relatorio_fluxo_ago_df.copy()\n",
    "    quantidade_cols = [col for col in relatorio_fluxo_ago_clean.columns if col.startswith('qtd_')]\n",
    "    for col in quantidade_cols:\n",
    "        relatorio_fluxo_ago_clean[col] = pd.to_numeric(relatorio_fluxo_ago_clean[col], errors='coerce')\n",
    "\n",
    "    if 'data' in relatorio_fluxo_ago_clean.columns:\n",
    "        relatorio_fluxo_ago_clean['data'] = pd.to_datetime(relatorio_fluxo_ago_clean['data'], errors='coerce')\n",
    "    if 'equipamento' in relatorio_fluxo_ago_clean.columns and relatorio_fluxo_ago_clean['equipamento'].dtype == 'object':\n",
    "        relatorio_fluxo_ago_clean['equipamento'] = relatorio_fluxo_ago_clean['equipamento'].astype(str).str.strip()\n",
    "    if 'faixa' in relatorio_fluxo_ago_clean.columns and relatorio_fluxo_ago_clean['faixa'].dtype == 'object':\n",
    "        relatorio_fluxo_ago_clean['faixa'] = relatorio_fluxo_ago_clean['faixa'].astype(str).str.strip()\n",
    "    if 'hora' in relatorio_fluxo_ago_clean.columns:\n",
    "        relatorio_fluxo_ago_clean['hora'] = pd.to_numeric(relatorio_fluxo_ago_clean['hora'], errors='coerce')\n",
    "    print(f\"   [OK] Relatório Agosto limpo: {relatorio_fluxo_ago_clean.shape[0]} registros\")\n",
    "else:\n",
    "    relatorio_fluxo_ago_clean = None\n",
    "    print(\"   [ATENCAO]  Relatório Agosto não disponível\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2881f226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIGURANDO] Limpando dados dos relatórios de fluxo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\AppData\\Local\\Temp\\ipykernel_14176\\542142663.py:60: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  relatorio_fluxo_mai_clean['data'] = pd.to_datetime(relatorio_fluxo_mai_clean['data'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [OK] Relatório Fevereiro limpo: 283999 registros\n",
      "   [OK] Relatório Fevereiro limpo: 273529 registros\n",
      "   [OK] Relatório Fevereiro limpo: 301067 registros\n",
      "   [OK] Relatório Fevereiro limpo: 292669 registros\n",
      "   [OK] Relatório Fevereiro limpo: 300932 registros\n",
      "   [OK] Relatório Fevereiro limpo: 289577 registros\n",
      "   [OK] Relatório Fevereiro limpo: 297149 registros\n",
      "   [OK] Relatório Agosto limpo: 298228 registros\n",
      "   [OK] Valores nulos Fevereiro: 283999\n",
      "   [OK] Valores nulos Fevereiro: 0\n",
      "   [OK] Valores nulos Fevereiro: 301067\n",
      "   [OK] Valores nulos Fevereiro: 292669\n",
      "   [OK] Valores nulos Fevereiro: 1203739\n",
      "   [OK] Valores nulos Fevereiro: 0\n",
      "   [OK] Valores nulos Fevereiro: 297149\n",
      "   [OK] Valores nulos Agosto: 0\n"
     ]
    }
   ],
   "source": [
    "# 6. LIMPEZA DOS RELATÓRIOS DE FLUXO (AGOSTO E FEVEREIRO)\n",
    "print(\"[CONFIGURANDO] Limpando dados dos relatórios de fluxo...\")\n",
    "\n",
    "# Limpeza do relatório de Agosto\n",
    "relatorio_fluxo_ago_clean = relatorio_fluxo_ago_df.copy()\n",
    "quantidade_cols = [col for col in relatorio_fluxo_ago_clean.columns if col.startswith('qtd_')]\n",
    "for col in quantidade_cols:\n",
    "    relatorio_fluxo_ago_clean[col] = pd.to_numeric(relatorio_fluxo_ago_clean[col], errors='coerce')\n",
    "\n",
    "relatorio_fluxo_ago_clean['data'] = pd.to_datetime(relatorio_fluxo_ago_clean['data'], errors='coerce')\n",
    "relatorio_fluxo_ago_clean['equipamento'] = relatorio_fluxo_ago_clean['equipamento'].str.strip()\n",
    "relatorio_fluxo_ago_clean['faixa'] = relatorio_fluxo_ago_clean['faixa'].str.strip()\n",
    "relatorio_fluxo_ago_clean['hora'] = pd.to_numeric(relatorio_fluxo_ago_clean['hora'], errors='coerce')\n",
    "\n",
    "# Limpeza do relatório de Fevereiro\n",
    "relatorio_fluxo_fev_clean = relatorio_fluxo_fev_df.copy()\n",
    "for col in quantidade_cols:\n",
    "    relatorio_fluxo_fev_clean[col] = pd.to_numeric(relatorio_fluxo_fev_clean[col], errors='coerce')\n",
    "\n",
    "relatorio_fluxo_fev_clean['data'] = pd.to_datetime(relatorio_fluxo_fev_clean['data'], errors='coerce')\n",
    "relatorio_fluxo_fev_clean['equipamento'] = relatorio_fluxo_fev_clean['equipamento'].str.strip()\n",
    "relatorio_fluxo_fev_clean['faixa'] = relatorio_fluxo_fev_clean['faixa'].str.strip()\n",
    "relatorio_fluxo_fev_clean['hora'] = pd.to_numeric(relatorio_fluxo_fev_clean['hora'], errors='coerce')\n",
    "\n",
    "# Limpeza do relatório de Janeiro\n",
    "relatorio_fluxo_jan_clean = relatorio_fluxo_jan_df.copy()\n",
    "for col in quantidade_cols:\n",
    "    relatorio_fluxo_jan_clean[col] = pd.to_numeric(relatorio_fluxo_jan_clean[col], errors='coerce')\n",
    "\n",
    "relatorio_fluxo_jan_clean['data'] = pd.to_datetime(relatorio_fluxo_jan_clean['data'], errors='coerce')\n",
    "relatorio_fluxo_jan_clean['equipamento'] = relatorio_fluxo_jan_clean['equipamento'].str.strip()\n",
    "relatorio_fluxo_jan_clean['faixa'] = relatorio_fluxo_jan_clean['faixa'].str.strip()\n",
    "relatorio_fluxo_jan_clean['hora'] = pd.to_numeric(relatorio_fluxo_jan_clean['hour'], errors='coerce')\n",
    "\n",
    "# Limpeza do relatório de Março\n",
    "relatorio_fluxo_mar_clean = relatorio_fluxo_mar_df.copy()\n",
    "for col in quantidade_cols:\n",
    "    relatorio_fluxo_mar_clean[col] = pd.to_numeric(relatorio_fluxo_mar_clean[col], errors='coerce')\n",
    "\n",
    "relatorio_fluxo_mar_clean['data'] = pd.to_datetime(relatorio_fluxo_mar_clean['data'], errors='coerce')\n",
    "relatorio_fluxo_mar_clean['equipamento'] = relatorio_fluxo_mar_clean['equipamento'].str.strip()\n",
    "relatorio_fluxo_mar_clean['faixa'] = relatorio_fluxo_mar_clean['faixa'].str.strip()\n",
    "relatorio_fluxo_mar_clean['hora'] = pd.to_numeric(relatorio_fluxo_mar_clean['hora'], errors='coerce')\n",
    "\n",
    "# Limpeza do relatório de Abril\n",
    "relatorio_fluxo_abr_clean = relatorio_fluxo_abr_df.copy()\n",
    "for col in quantidade_cols:\n",
    "    relatorio_fluxo_abr_clean[col] = pd.to_numeric(relatorio_fluxo_abr_clean[col], errors='coerce')\n",
    "\n",
    "relatorio_fluxo_abr_clean['data'] = pd.to_datetime(relatorio_fluxo_abr_clean['data'], errors='coerce')\n",
    "relatorio_fluxo_abr_clean['equipamento'] = relatorio_fluxo_abr_clean['equipamento'].str.strip()\n",
    "relatorio_fluxo_abr_clean['faixa'] = relatorio_fluxo_abr_clean['faixa'].str.strip()\n",
    "relatorio_fluxo_abr_clean['hora'] = pd.to_numeric(relatorio_fluxo_abr_clean['hora'], errors='coerce')\n",
    "\n",
    "# Limpeza do relatório de Maio\n",
    "relatorio_fluxo_mai_clean = relatorio_fluxo_mai_df.copy()\n",
    "for col in quantidade_cols:\n",
    "    relatorio_fluxo_mai_clean[col] = pd.to_numeric(relatorio_fluxo_mai_clean[col], errors='coerce')\n",
    "\n",
    "relatorio_fluxo_mai_clean['data'] = pd.to_datetime(relatorio_fluxo_mai_clean['data'], errors='coerce')\n",
    "relatorio_fluxo_mai_clean['equipamento'] = relatorio_fluxo_mai_clean['equipamento'].astype(str).str.strip()\n",
    "relatorio_fluxo_mai_clean['faixa'] = relatorio_fluxo_mai_clean['faixa'].str.strip()\n",
    "relatorio_fluxo_mai_clean['hora'] = pd.to_numeric(relatorio_fluxo_mai_clean['hora'], errors='coerce')\n",
    "\n",
    "# Limpeza do relatório de Junho\n",
    "relatorio_fluxo_jun_clean = relatorio_fluxo_jun_df.copy()\n",
    "for col in quantidade_cols:\n",
    "    relatorio_fluxo_jun_clean[col] = pd.to_numeric(relatorio_fluxo_jun_clean[col], errors='coerce')\n",
    "\n",
    "relatorio_fluxo_jun_clean['data'] = pd.to_datetime(relatorio_fluxo_jun_clean['data'], errors='coerce')\n",
    "relatorio_fluxo_jun_clean['equipamento'] = relatorio_fluxo_jun_clean['equipamento'].str.strip()\n",
    "relatorio_fluxo_jun_clean['faixa'] = relatorio_fluxo_jun_clean['faixa'].str.strip()\n",
    "relatorio_fluxo_jun_clean['hora'] = pd.to_numeric(relatorio_fluxo_jun_clean['hora'], errors='coerce')\n",
    "\n",
    "# Limpeza do relatório de Julho\n",
    "relatorio_fluxo_jul_clean = relatorio_fluxo_jul_df.copy()\n",
    "for col in quantidade_cols:\n",
    "    relatorio_fluxo_jul_clean[col] = pd.to_numeric(relatorio_fluxo_jul_clean[col], errors='coerce')\n",
    "\n",
    "relatorio_fluxo_jul_clean['data'] = pd.to_datetime(relatorio_fluxo_jul_clean['data'], errors='coerce')\n",
    "relatorio_fluxo_jul_clean['equipamento'] = relatorio_fluxo_jul_clean['equipamento'].str.strip()\n",
    "relatorio_fluxo_jul_clean['faixa'] = relatorio_fluxo_jul_clean['faixa'].str.strip()\n",
    "relatorio_fluxo_jul_clean['hora'] = pd.to_numeric(relatorio_fluxo_jul_clean['hora'], errors='coerce')\n",
    "\n",
    "print(f\"   [OK] Relatório Fevereiro limpo: {relatorio_fluxo_jan_clean.shape[0]} registros\")\n",
    "print(f\"   [OK] Relatório Fevereiro limpo: {relatorio_fluxo_fev_clean.shape[0]} registros\")\n",
    "print(f\"   [OK] Relatório Fevereiro limpo: {relatorio_fluxo_mar_clean.shape[0]} registros\")\n",
    "print(f\"   [OK] Relatório Fevereiro limpo: {relatorio_fluxo_abr_clean.shape[0]} registros\")\n",
    "print(f\"   [OK] Relatório Fevereiro limpo: {relatorio_fluxo_mai_clean.shape[0]} registros\")\n",
    "print(f\"   [OK] Relatório Fevereiro limpo: {relatorio_fluxo_jun_clean.shape[0]} registros\")\n",
    "print(f\"   [OK] Relatório Fevereiro limpo: {relatorio_fluxo_jul_clean.shape[0]} registros\")\n",
    "print(f\"   [OK] Relatório Agosto limpo: {relatorio_fluxo_ago_clean.shape[0]} registros\")\n",
    "\n",
    "print(f\"   [OK] Valores nulos Fevereiro: {relatorio_fluxo_jan_clean.isnull().sum().sum()}\")\n",
    "print(f\"   [OK] Valores nulos Fevereiro: {relatorio_fluxo_fev_clean.isnull().sum().sum()}\")\n",
    "print(f\"   [OK] Valores nulos Fevereiro: {relatorio_fluxo_mar_clean.isnull().sum().sum()}\")\n",
    "print(f\"   [OK] Valores nulos Fevereiro: {relatorio_fluxo_abr_clean.isnull().sum().sum()}\")\n",
    "print(f\"   [OK] Valores nulos Fevereiro: {relatorio_fluxo_mai_clean.isnull().sum().sum()}\")\n",
    "print(f\"   [OK] Valores nulos Fevereiro: {relatorio_fluxo_jun_clean.isnull().sum().sum()}\")\n",
    "print(f\"   [OK] Valores nulos Fevereiro: {relatorio_fluxo_jul_clean.isnull().sum().sum()}\")\n",
    "print(f\"   [OK] Valores nulos Agosto: {relatorio_fluxo_ago_clean.isnull().sum().sum()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f0cc9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISES EXPLORATÓRIAS ===\n",
      "\n",
      "[SINAL] ANÁLISE DOS SEMÁFOROS:\n",
      "   - Total de semáforos: 712\n",
      "   - Bairros únicos: 86\n",
      "   - Tipos de funcionamento: {'Veicular': 336, 'Ocasional/Ped.': 217, 'Veic.C/Ped.Paral.': 58, 'Veic.C/Ped.Ocas.': 48, 'Veic.C/Ped.': 32, 'Pedestre': 14, 'Veic.c/Ped.Ocas.': 6, 'Veic.C/Laço Det.': 1}\n",
      "   - Coordenadas válidas: 711\n",
      "\n",
      "[ANALISE] ANÁLISE DOS EQUIPAMENTOS DE MEDIÇÃO:\n",
      "   - Total de equipamentos: 62\n",
      "   - Colunas disponíveis: ['_id', 'equipamento', 'tipo', 'logradouro', 'velocidade_via', 'latitude', 'longitude']\n",
      "\n",
      "[VEICULO] ANÁLISE DO FLUXO DE VEÍCULOS:\n",
      "   - Registros de fluxo por hora: 672\n",
      "   - Equipamentos únicos: 28\n",
      "   - Total de veículos registrados: 15,295,616\n",
      "\n",
      "[RAPIDO] ANÁLISE DE VELOCIDADE EM 15 MINUTOS:\n",
      "   - Registros de velocidade: 342796\n",
      "   - Período dos dados: 2025-01-01 00:00:00 a 2025-01-31 00:00:00\n",
      "   - Equipamentos únicos: 40\n",
      "\n",
      "[CRESCIMENTO] ANÁLISE DOS RELATÓRIOS DE FLUXO:\n",
      "   - Registros Janeiro 2025: 283999\n",
      "   - Registros Fevereiro 2025: 273529\n",
      "   - Registros Março 2025: 301067\n",
      "   - Registros Abril 2025: 292669\n",
      "   - Registros Maio 2025: 300932\n",
      "   - Registros Junho 2025: 289577\n",
      "   - Registros Julho 2025: 297149\n",
      "   - Registros Agosto 2025: 298228\n",
      "   - Total de registros: 2337150\n"
     ]
    }
   ],
   "source": [
    "# ANÁLISES EXPLORATÓRIAS E ESTATÍSTICAS\n",
    "\n",
    "print(\"=== ANÁLISES EXPLORATÓRIAS ===\\n\")\n",
    "\n",
    "# 1. ANÁLISE DOS SEMÁFOROS\n",
    "if semaforos_clean is not None:\n",
    "    print(\"[SINAL] ANÁLISE DOS SEMÁFOROS:\")\n",
    "    print(f\"   - Total de semáforos: {len(semaforos_clean)}\")\n",
    "    print(f\"   - Bairros únicos: {semaforos_clean['bairro'].nunique()}\")\n",
    "    print(f\"   - Tipos de funcionamento: {semaforos_clean['funcionamento'].value_counts().to_dict()}\")\n",
    "    print(f\"   - Coordenadas válidas: {semaforos_clean[['latitude', 'longitude']].notna().all(axis=1).sum()}\")\n",
    "else:\n",
    "    print(\"[SINAL] SEMÁFOROS: Não disponível\")\n",
    "\n",
    "# 2. ANÁLISE DOS EQUIPAMENTOS DE MEDIÇÃO\n",
    "if equip_med_vel_clean is not None:\n",
    "    print(\"\\n[ANALISE] ANÁLISE DOS EQUIPAMENTOS DE MEDIÇÃO:\")\n",
    "    print(f\"   - Total de equipamentos: {len(equip_med_vel_clean)}\")\n",
    "    print(f\"   - Colunas disponíveis: {list(equip_med_vel_clean.columns)}\")\n",
    "    \n",
    "    # Análises condicionais baseadas nas colunas disponíveis\n",
    "    if 'velocidade_fiscalizada' in equip_med_vel_clean.columns:\n",
    "        print(f\"   - Velocidade fiscalizada média: {equip_med_vel_clean['velocidade_fiscalizada'].mean():.1f} km/h\")\n",
    "    if 'vmd' in equip_med_vel_clean.columns:\n",
    "        print(f\"   - VMD médio: {equip_med_vel_clean['vmd'].mean():.0f} veículos\")\n",
    "    if 'faixas_fiscalizadas' in equip_med_vel_clean.columns:\n",
    "        print(f\"   - Faixas fiscalizadas: {equip_med_vel_clean['faixas_fiscalizadas'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"\\n[ANALISE] EQUIPAMENTOS DE MEDIÇÃO: Não disponível\")\n",
    "\n",
    "# 3. ANÁLISE DO FLUXO DE VEÍCULOS\n",
    "if fluxo_veiculos_hora_clean is not None:\n",
    "    print(\"\\n[VEICULO] ANÁLISE DO FLUXO DE VEÍCULOS:\")\n",
    "    print(f\"   - Registros de fluxo por hora: {len(fluxo_veiculos_hora_clean)}\")\n",
    "    print(f\"   - Equipamentos únicos: {fluxo_veiculos_hora_clean['equipamento'].nunique()}\")\n",
    "    print(f\"   - Total de veículos registrados: {fluxo_veiculos_hora_clean['quanttotal'].sum():,.0f}\")\n",
    "else:\n",
    "    print(\"\\n[VEICULO] FLUXO DE VEÍCULOS: Não disponível\")\n",
    "\n",
    "# 4. ANÁLISE DOS DADOS DE VELOCIDADE EM 15 MINUTOS\n",
    "if fluxo_velocidade_15min_clean is not None:\n",
    "    print(\"\\n[RAPIDO] ANÁLISE DE VELOCIDADE EM 15 MINUTOS:\")\n",
    "    print(f\"   - Registros de velocidade: {len(fluxo_velocidade_15min_clean)}\")\n",
    "    print(f\"   - Período dos dados: {fluxo_velocidade_15min_clean['data'].min()} a {fluxo_velocidade_15min_clean['data'].max()}\")\n",
    "    print(f\"   - Equipamentos únicos: {fluxo_velocidade_15min_clean['equipamento'].nunique()}\")\n",
    "else:\n",
    "    print(\"\\n[RAPIDO] VELOCIDADE EM 15 MINUTOS: Não disponível\")\n",
    "\n",
    "# 5. ANÁLISE DOS RELATÓRIOS DE FLUXO\n",
    "if relatorio_fluxo_jan_clean is not None and relatorio_fluxo_fev_clean is not None and relatorio_fluxo_mar_clean is not None and relatorio_fluxo_abr_clean is not None and relatorio_fluxo_mai_clean is not None and relatorio_fluxo_jun_clean is not None and relatorio_fluxo_jul_clean is not None and relatorio_fluxo_ago_clean is not None:\n",
    "    print(\"\\n[CRESCIMENTO] ANÁLISE DOS RELATÓRIOS DE FLUXO:\")\n",
    "    print(f\"   - Registros Janeiro 2025: {len(relatorio_fluxo_jan_clean)}\")\n",
    "    print(f\"   - Registros Fevereiro 2025: {len(relatorio_fluxo_fev_clean)}\")\n",
    "    print(f\"   - Registros Março 2025: {len(relatorio_fluxo_mar_clean)}\")\n",
    "    print(f\"   - Registros Abril 2025: {len(relatorio_fluxo_abr_clean)}\")\n",
    "    print(f\"   - Registros Maio 2025: {len(relatorio_fluxo_mai_clean)}\")\n",
    "    print(f\"   - Registros Junho 2025: {len(relatorio_fluxo_jun_clean)}\")\n",
    "    print(f\"   - Registros Julho 2025: {len(relatorio_fluxo_jul_clean)}\")\n",
    "    print(f\"   - Registros Agosto 2025: {len(relatorio_fluxo_ago_clean)}\")\n",
    "    print(f\"   - Total de registros: {len(relatorio_fluxo_ago_clean) + len(relatorio_fluxo_fev_clean) + len(relatorio_fluxo_jan_clean) + len(relatorio_fluxo_mar_clean) + len(relatorio_fluxo_abr_clean) + len(relatorio_fluxo_mai_clean) + len(relatorio_fluxo_jun_clean) + len(relatorio_fluxo_jul_clean)}\")\n",
    "else:\n",
    "    print(\"\\n[CRESCIMENTO] RELATÓRIOS DE FLUXO: Parcialmente disponível\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae909614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SALVANDO DADOS PROCESSADOS ===\n",
      "\n",
      "[OK] Salvo: semaforos_clean.csv (712 registros)\n",
      "[OK] Salvo: equipamentos_medicao_velocidade_clean.csv (62 registros)\n",
      "[OK] Salvo: fluxo_veiculos_hora_clean.csv (672 registros)\n",
      "[OK] Salvo: fluxo_velocidade_15min_clean.csv (342796 registros)\n",
      "[OK] Salvo: monitoramento_cttu_clean.csv (54 registros)\n",
      "[OK] Salvo: relatorio_fluxo_janeiro_2025_clean.csv (283999 registros)\n",
      "[OK] Salvo: relatorio_fluxo_fevereiro_2025_clean.csv (273529 registros)\n",
      "[OK] Salvo: relatorio_fluxo_marco_2025_clean.csv (301067 registros)\n",
      "[OK] Salvo: relatorio_fluxo_abril_2025_clean.csv (292669 registros)\n",
      "[OK] Salvo: relatorio_fluxo_maio_2025_clean.csv (300932 registros)\n",
      "[OK] Salvo: relatorio_fluxo_junho_2025_clean.csv (289577 registros)\n",
      "[OK] Salvo: relatorio_fluxo_julho_2025_clean.csv (297149 registros)\n",
      "[OK] Salvo: relatorio_fluxo_agosto_2025_clean.csv (298228 registros)\n",
      "\n",
      "[SUCESSO] Dados processados salvos em 'c:\\Users\\berna\\OneDrive\\Documentos\\Computação\\projetos\\urban-flow-project-g16\\data\\processed'\n",
      "[ARQUIVO] Total de arquivos salvos: 13\n",
      "\n",
      "=== RESUMO FINAL ===\n",
      "[ANALISE] Total de registros processados: 2,681,446\n",
      "[ARMAZENANDO] Tamanho total estimado: 708.33 MB\n"
     ]
    }
   ],
   "source": [
    "# SALVAR DADOS PROCESSADOS\n",
    "\n",
    "print(\"=== SALVANDO DADOS PROCESSADOS ===\\n\")\n",
    "\n",
    "import os\n",
    "\n",
    "# Criar diretório de dados processados se não existir\n",
    "data_processed_path = os.path.join(project_root, \"data\", \"processed\")\n",
    "os.makedirs(data_processed_path, exist_ok=True)\n",
    "\n",
    "# Salvar apenas os datasets que foram processados\n",
    "datasets_clean = {\n",
    "    \"semaforos_clean.csv\": semaforos_clean,\n",
    "    \"equipamentos_medicao_velocidade_clean.csv\": equip_med_vel_clean,\n",
    "    \"fluxo_veiculos_hora_clean.csv\": fluxo_veiculos_hora_clean,\n",
    "    \"fluxo_velocidade_15min_clean.csv\": fluxo_velocidade_15min_clean,\n",
    "    \"monitoramento_cttu_clean.csv\": monitoramento_cttu_df,  # Este não foi limpo ainda\n",
    "    \"relatorio_fluxo_janeiro_2025_clean.csv\": relatorio_fluxo_jan_clean,\n",
    "    \"relatorio_fluxo_fevereiro_2025_clean.csv\": relatorio_fluxo_fev_clean,\n",
    "    \"relatorio_fluxo_marco_2025_clean.csv\": relatorio_fluxo_mar_clean,\n",
    "    \"relatorio_fluxo_abril_2025_clean.csv\": relatorio_fluxo_abr_clean,\n",
    "    \"relatorio_fluxo_maio_2025_clean.csv\": relatorio_fluxo_mai_clean,\n",
    "    \"relatorio_fluxo_junho_2025_clean.csv\": relatorio_fluxo_jun_clean,\n",
    "    \"relatorio_fluxo_julho_2025_clean.csv\": relatorio_fluxo_jul_clean,\n",
    "    \"relatorio_fluxo_agosto_2025_clean.csv\": relatorio_fluxo_ago_clean\n",
    "}\n",
    "\n",
    "# Filtrar apenas datasets que não são None\n",
    "datasets_para_salvar = {k: v for k, v in datasets_clean.items() if v is not None}\n",
    "\n",
    "for filename, df in datasets_para_salvar.items():\n",
    "    filepath = os.path.join(data_processed_path, filename)\n",
    "    df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "    print(f\"[OK] Salvo: {filename} ({df.shape[0]} registros)\")\n",
    "\n",
    "# Mostrar quais datasets não foram salvos\n",
    "datasets_nao_salvos = {k: v for k, v in datasets_clean.items() if v is None}\n",
    "if datasets_nao_salvos:\n",
    "    print(f\"\\n[ATENCAO]  Datasets não salvos (não disponíveis): {list(datasets_nao_salvos.keys())}\")\n",
    "\n",
    "print(f\"\\n[SUCESSO] Dados processados salvos em '{data_processed_path}'\")\n",
    "print(f\"[ARQUIVO] Total de arquivos salvos: {len(datasets_para_salvar)}\")\n",
    "\n",
    "# Resumo final\n",
    "print(\"\\n=== RESUMO FINAL ===\")\n",
    "total_registros = sum(df.shape[0] for df in datasets_para_salvar.values())\n",
    "print(f\"[ANALISE] Total de registros processados: {total_registros:,}\")\n",
    "print(f\"[ARMAZENANDO] Tamanho total estimado: {sum(df.memory_usage(deep=True).sum() for df in datasets_para_salvar.values()) / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ce384dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GERAÇÃO AUTOMÁTICA DE SCHEMAS SQL ===\n",
      "\n",
      "[RESUMO] Gerando schemas SQL automaticamente...\n",
      "[OK] Schema gerado: semaforos\n",
      "[OK] Schema gerado: equipamentos_medicao_velocidade\n",
      "[OK] Schema gerado: fluxo_veiculos_hora\n",
      "[OK] Schema gerado: fluxo_velocidade_15min\n",
      "[OK] Schema gerado: monitoramento_cttu\n",
      "[OK] Schema gerado: relatorio_fluxo_agosto\n",
      "[OK] Schema gerado: relatorio_fluxo_fevereiro\n",
      "[OK] Schema gerado: relatorio_fluxo_janeiro\n",
      "[OK] Schema gerado: relatorio_fluxo_marco\n",
      "[OK] Schema gerado: relatorio_fluxo_abril\n",
      "[OK] Schema gerado: relatorio_fluxo_maio\n",
      "[OK] Schema gerado: relatorio_fluxo_junho\n",
      "[OK] Schema gerado: relatorio_fluxo_julho\n",
      "[ARMAZENANDO] Schema salvo: semaforos_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: equipamentos_medicao_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: fluxo_veiculos_hora_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: fluxo_velocidade_15min_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: monitoramento_cttu_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: relatorio_fluxo_agosto_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: relatorio_fluxo_fevereiro_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: relatorio_fluxo_janeiro_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: relatorio_fluxo_marco_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: relatorio_fluxo_abril_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: relatorio_fluxo_maio_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: relatorio_fluxo_junho_schema.sql\n",
      "[ARMAZENANDO] Schema salvo: relatorio_fluxo_julho_schema.sql\n",
      "\n",
      "[SUCESSO] 13 schemas SQL gerados automaticamente!\n",
      "[ARQUIVO] Salvos em: c:\\Users\\berna\\OneDrive\\Documentos\\Computação\\projetos\\urban-flow-project-g16\\database\\schemas\n"
     ]
    }
   ],
   "source": [
    "# GERAÇÃO AUTOMÁTICA DE SCHEMAS SQL\n",
    "\n",
    "print(\"=== GERAÇÃO AUTOMÁTICA DE SCHEMAS SQL ===\\n\")\n",
    "\n",
    "def generate_sql_schema(df, table_name, primary_key=None):\n",
    "    \"\"\"Gera schema SQL automaticamente baseado no DataFrame\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    \n",
    "    schema_lines = [f\"CREATE TABLE IF NOT EXISTS {table_name} (\"]\n",
    "    \n",
    "    # Adicionar colunas\n",
    "    for i, (col, dtype) in enumerate(df.dtypes.items()):\n",
    "        # Converter tipos do pandas para SQL\n",
    "        if dtype == 'int64':\n",
    "            sql_type = \"INTEGER\"\n",
    "        elif dtype == 'float64':\n",
    "            sql_type = \"DECIMAL(10, 2)\"\n",
    "        elif dtype == 'object':\n",
    "            # Para strings, verificar tamanho máximo\n",
    "            try:\n",
    "                max_len = df[col].astype(str).str.len().max()\n",
    "                if max_len > 255:\n",
    "                    sql_type = \"TEXT\"\n",
    "                else:\n",
    "                    sql_type = f\"VARCHAR({max(255, max_len)})\"\n",
    "            except:\n",
    "                sql_type = \"TEXT\"\n",
    "        elif 'datetime' in str(dtype):\n",
    "            sql_type = \"TIMESTAMP\"\n",
    "        else:\n",
    "            sql_type = \"TEXT\"\n",
    "        \n",
    "        # CORREÇÕES ESPECÍFICAS PARA TIPOS DE DADOS\n",
    "        # Coordenadas com precisão correta\n",
    "        if col in ['latitude']:\n",
    "            sql_type = \"DECIMAL(10, 8)\"\n",
    "        elif col in ['longitude']:\n",
    "            sql_type = \"DECIMAL(11, 8)\"\n",
    "        \n",
    "        # Horários como TIME em vez de TIMESTAMP\n",
    "        if col in ['horainicio', 'horafinal']:\n",
    "            sql_type = \"TIME\"\n",
    "        \n",
    "        # Datas como DATE em vez de TIMESTAMP\n",
    "        if col == 'data' and 'datetime' in str(dtype):\n",
    "            sql_type = \"DATE\"\n",
    "        \n",
    "        # Adicionar PRIMARY KEY se especificado\n",
    "        if primary_key and col == primary_key:\n",
    "            if col == '_id':\n",
    "                sql_type += \" PRIMARY KEY\"  # INTEGER PRIMARY KEY\n",
    "            else:\n",
    "                sql_type += \" SERIAL PRIMARY KEY\"  # SERIAL PRIMARY KEY\n",
    "        elif not primary_key and i == 0:\n",
    "            sql_type += \" SERIAL PRIMARY KEY\"\n",
    "        \n",
    "        col_name = col.replace('-', '_')\n",
    "        schema_lines.append(f\"    {col_name} {sql_type},\")\n",
    "    \n",
    "    # Adicionar campo created_at\n",
    "    schema_lines.append(\"    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\")\n",
    "    schema_lines.append(\");\")\n",
    "    \n",
    "    return \"\\n\".join(schema_lines)\n",
    "\n",
    "# Gerar schemas para todos os datasets processados\n",
    "print(\"[RESUMO] Gerando schemas SQL automaticamente...\")\n",
    "\n",
    "schemas_generated = {}\n",
    "\n",
    "# 1. Semáforos - usar _id como PRIMARY KEY\n",
    "if semaforos_clean is not None:\n",
    "    schema = generate_sql_schema(semaforos_clean, \"semaforos\", \"_id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"semaforos_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: semaforos\")\n",
    "\n",
    "# 2. Equipamentos de medição - usar _id como PRIMARY KEY\n",
    "if equip_med_vel_clean is not None:\n",
    "    schema = generate_sql_schema(equip_med_vel_clean, \"equipamentos_medicao_velocidade\", \"_id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"equipamentos_medicao_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: equipamentos_medicao_velocidade\")\n",
    "\n",
    "# 3. Fluxo de veículos por hora - usar id SERIAL\n",
    "if fluxo_veiculos_hora_clean is not None:\n",
    "    schema = generate_sql_schema(fluxo_veiculos_hora_clean, \"fluxo_veiculos_hora\", \"id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"fluxo_veiculos_hora_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: fluxo_veiculos_hora\")\n",
    "\n",
    "# 4. Fluxo e velocidade 15min - usar id SERIAL\n",
    "if fluxo_velocidade_15min_clean is not None:\n",
    "    schema = generate_sql_schema(fluxo_velocidade_15min_clean, \"fluxo_velocidade_15min\", \"id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"fluxo_velocidade_15min_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: fluxo_velocidade_15min\")\n",
    "\n",
    "# 5. Monitoramento CTTU - usar id SERIAL\n",
    "if monitoramento_cttu_df is not None:\n",
    "    schema = generate_sql_schema(monitoramento_cttu_df, \"monitoramento_cttu\", \"id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"monitoramento_cttu_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: monitoramento_cttu\")\n",
    "\n",
    "# 6. Relatório fluxo Agosto - usar id SERIAL\n",
    "if relatorio_fluxo_ago_clean is not None:\n",
    "    schema = generate_sql_schema(relatorio_fluxo_ago_clean, \"relatorio_fluxo_agosto\", \"id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"relatorio_fluxo_agosto_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: relatorio_fluxo_agosto\")\n",
    "\n",
    "# 7. Relatório fluxo Fevereiro - usar id SERIAL\n",
    "if relatorio_fluxo_fev_clean is not None:\n",
    "    schema = generate_sql_schema(relatorio_fluxo_fev_clean, \"relatorio_fluxo_fevereiro\", \"id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"relatorio_fluxo_fevereiro_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: relatorio_fluxo_fevereiro\")\n",
    "\n",
    "if relatorio_fluxo_jan_clean is not None:\n",
    "    schema = generate_sql_schema(relatorio_fluxo_jan_clean, \"relatorio_fluxo_janeiro\", \"id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"relatorio_fluxo_janeiro_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: relatorio_fluxo_janeiro\")\n",
    "\n",
    "if relatorio_fluxo_mar_clean is not None:\n",
    "    schema = generate_sql_schema(relatorio_fluxo_mar_clean, \"relatorio_fluxo_marco\", \"id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"relatorio_fluxo_marco_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: relatorio_fluxo_marco\")\n",
    "\n",
    "if relatorio_fluxo_abr_clean is not None:\n",
    "    schema = generate_sql_schema(relatorio_fluxo_abr_clean, \"relatorio_fluxo_abril\", \"id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"relatorio_fluxo_abril_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: relatorio_fluxo_abril\")\n",
    "\n",
    "if relatorio_fluxo_mai_clean is not None:\n",
    "    schema = generate_sql_schema(relatorio_fluxo_mai_clean, \"relatorio_fluxo_maio\", \"id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"relatorio_fluxo_maio_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: relatorio_fluxo_maio\")\n",
    "\n",
    "if relatorio_fluxo_jun_clean is not None:\n",
    "    schema = generate_sql_schema(relatorio_fluxo_jun_clean, \"relatorio_fluxo_junho\", \"id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"relatorio_fluxo_junho_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: relatorio_fluxo_junho\")\n",
    "\n",
    "if relatorio_fluxo_jul_clean is not None:\n",
    "    schema = generate_sql_schema(relatorio_fluxo_jul_clean, \"relatorio_fluxo_julho\", \"id\")\n",
    "    if schema:\n",
    "        schemas_generated[\"relatorio_fluxo_julho_schema.sql\"] = schema\n",
    "        print(\"[OK] Schema gerado: relatorio_fluxo_julho\")\n",
    "        \n",
    "# Salvar schemas em arquivos\n",
    "if schemas_generated:\n",
    "    database_schemas_path = os.path.join(project_root, \"database\", \"schemas\")\n",
    "    os.makedirs(database_schemas_path, exist_ok=True)\n",
    "    \n",
    "    for filename, schema in schemas_generated.items():\n",
    "        filepath = os.path.join(database_schemas_path, filename)\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(schema)\n",
    "        print(f\"[ARMAZENANDO] Schema salvo: {filename}\")\n",
    "    \n",
    "    print(f\"\\n[SUCESSO] {len(schemas_generated)} schemas SQL gerados automaticamente!\")\n",
    "    print(f\"[ARQUIVO] Salvos em: {database_schemas_path}\")\n",
    "else:\n",
    "    print(\"[ATENCAO]  Nenhum dataset processado encontrado para gerar schemas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7584d08",
   "metadata": {},
   "source": [
    "### Limpando faixaazul.geojson para Grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4980c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON carregado com sucesso!\n",
      "Número de faixas: 12\n",
      "Arquivo salvo: ../../data/processed/faixaazul_clean.geojson\n",
      "Servidor rodando em http://localhost:8080/\n",
      "Acesse no Grafana: http://localhost:8080/faixaazul_clean.geojson\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import geopandas as gpd\n",
    "from http.server import SimpleHTTPRequestHandler, HTTPServer\n",
    "import threading\n",
    "import os\n",
    "\n",
    "geojson_path = \"../../data/raw/faixaazul.geojson\"\n",
    "\n",
    "# Ler e validar o .geojson\n",
    "try:\n",
    "    gdf = gpd.read_file(geojson_path)\n",
    "    print(\"GeoJSON carregado com sucesso!\")\n",
    "    print(\"Número de faixas:\", len(gdf))\n",
    "except Exception as e:\n",
    "    print(\"Erro ao ler o GeoJSON:\", e)\n",
    "\n",
    "# Garantir que o CRS está em WGS84 (EPSG:4326)\n",
    "if gdf.crs is None or gdf.crs.to_string() != \"EPSG:4326\":\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "    print(\"Sistema de coordenadas ajustado para WGS84 (EPSG:4326)\")\n",
    "\n",
    "# Salvar uma versão \"limpa\" do GeoJSON\n",
    "clean_path = \"../../data/processed/faixaazul_clean.geojson\"\n",
    "gdf.to_file(clean_path, driver=\"GeoJSON\")\n",
    "print(f\"Arquivo salvo: {clean_path}\")\n",
    "\n",
    "# Servidor HTTP para expor o arquivo\n",
    "\n",
    "# Função para iniciar servidor simples\n",
    "def start_server(directory=\".\", port=8080):\n",
    "    os.chdir(directory)\n",
    "    handler = SimpleHTTPRequestHandler\n",
    "    httpd = HTTPServer((\"\", port), handler)\n",
    "    print(f\"Servidor rodando em http://localhost:{port}/\")\n",
    "    print(f\"Acesse no Grafana: http://localhost:{port}/{os.path.basename(clean_path)}\")\n",
    "    httpd.serve_forever()\n",
    "\n",
    "# Rodar o servidor em thread paralela\n",
    "thread = threading.Thread(target=start_server, args=(\".\", 8080))\n",
    "thread.daemon = True\n",
    "thread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
